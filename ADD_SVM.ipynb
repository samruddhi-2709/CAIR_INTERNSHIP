{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HY87BCnOWP0G",
        "outputId": "cc162774-96f9-4045-ad4c-3eb90519ea69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "S_-qZZvqWdVL"
      },
      "outputs": [],
      "source": [
        "# Path to the directory containing the audio files\n",
        "audio_files_dir = '/content/drive/MyDrive/ADD_ASV_DATA/LA/ASVspoof2019_LA_train/flac'\n",
        "\n",
        "# Path to the protocol file\n",
        "protocol_file_path = '/content/drive/MyDrive/ADD_ASV_DATA/LA/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.train.trn.txt'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkhTmmL9WwJ6",
        "outputId": "28c67ecd-dfde-4fd7-b827-a9fcc09196c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  SpeakerID      FileName Env Label SpoofType\n",
            "0   LA_0079  LA_T_1138215   -     -  bonafide\n",
            "1   LA_0079  LA_T_1271820   -     -  bonafide\n",
            "2   LA_0079  LA_T_1272637   -     -  bonafide\n",
            "3   LA_0079  LA_T_1276960   -     -  bonafide\n",
            "4   LA_0079  LA_T_1341447   -     -  bonafide\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the protocol file\n",
        "protocol_df = pd.read_csv(protocol_file_path, delim_whitespace=True, header=None,\n",
        "                          names=['SpeakerID', 'FileName', 'Env', 'Label', 'SpoofType'])\n",
        "\n",
        "# Create a dictionary mapping file names to labels\n",
        "label_dict = dict(zip(protocol_df['FileName'], protocol_df['SpoofType']))\n",
        "\n",
        "# Print the first few entries to verify\n",
        "print(protocol_df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bac6qT0YWzgn",
        "outputId": "aaf351a5-8f92-42e0-b0ea-bec8f3a5c31d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total sampled files: 5160\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Get unique file names and labels\n",
        "file_names = protocol_df['FileName'].unique()\n",
        "labels = protocol_df['SpoofType'].unique()\n",
        "\n",
        "# Filter for each class\n",
        "bonafide_files = protocol_df[protocol_df['SpoofType'] == 'bonafide']['FileName']\n",
        "spoof_files = protocol_df[protocol_df['SpoofType'] == 'spoof']['FileName']\n",
        "\n",
        "# Define sample size\n",
        "sample_size = 2580  # Use all bonafide files and an equal number of spoof files\n",
        "\n",
        "# Sample files from each class\n",
        "sampled_bonafide_files = np.random.choice(bonafide_files, sample_size, replace=False)\n",
        "sampled_spoof_files = np.random.choice(spoof_files, sample_size, replace=False)\n",
        "\n",
        "# Combine into one list\n",
        "sampled_files = np.concatenate([sampled_bonafide_files, sampled_spoof_files])\n",
        "\n",
        "# Shuffle the files\n",
        "np.random.shuffle(sampled_files)\n",
        "\n",
        "print(f\"Total sampled files: {len(sampled_files)}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzXb9uyNXPh8",
        "outputId": "275b9c44-ef34-4424-d72a-2f6ef717eeed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of bonafide files: 2580\n",
            "Number of spoof files: 22800\n"
          ]
        }
      ],
      "source": [
        "num_bonafide = len(bonafide_files)\n",
        "num_spoof = len(spoof_files)\n",
        "\n",
        "print(f\"Number of bonafide files: {num_bonafide}\")\n",
        "print(f\"Number of spoof files: {num_spoof}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cO11iALfbICE"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Path to the folder where you want to store sampled files\n",
        "new_folder_path = '/content/drive/MyDrive/ADD_ASV_DATA/LA/ASVspoof2019_LA_train/ASVspoof2019_LA_Sampled'\n",
        "\n",
        "# Create the new folder if it doesn't exist\n",
        "if not os.path.exists(new_folder_path):\n",
        "    os.makedirs(new_folder_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "HjEvvc4vbmdO"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "\n",
        "# Path to the original folder with the audio files\n",
        "original_folder_path = '/content/drive/MyDrive/ADD_ASV_DATA/LA/ASVspoof2019_LA_train/flac'\n",
        "\n",
        "# Move sampled files to the new folder\n",
        "for file_name in sampled_files:\n",
        "    original_file_path = f'{original_folder_path}/{file_name}.flac'\n",
        "    new_file_path = f'{new_folder_path}/{file_name}.flac'\n",
        "    if os.path.exists(original_file_path):\n",
        "        shutil.copy(original_file_path, new_file_path)  # Use copy or move as needed\n",
        "    else:\n",
        "        print(f\"File {original_file_path} not found.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "05jxK6ZMcuQn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a170f764-ff66-44f6-a384-58d50783b5b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Labels file created at /content/drive/MyDrive/ADD_ASV_DATA/LA/ASVspoof2019_LA_train/labels.csv.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Define the paths\n",
        "new_folder_path = '/content/drive/MyDrive/ADD_ASV_DATA/LA/ASVspoof2019_LA_train/ASVspoof2019_LA_Sampled'\n",
        "\n",
        "# Prepare lists for file names and labels\n",
        "file_names = []\n",
        "labels = []\n",
        "\n",
        "# Append bonafide files\n",
        "for file_name in sampled_bonafide_files:\n",
        "    file_names.append(file_name)\n",
        "    labels.append(0)  # Label for bonafide\n",
        "\n",
        "# Append spoof files\n",
        "for file_name in sampled_spoof_files:\n",
        "    file_names.append(file_name)\n",
        "    labels.append(1)  # Label for spoof\n",
        "\n",
        "# Create a DataFrame\n",
        "labels_df = pd.DataFrame({\n",
        "    'FileName': file_names,\n",
        "    'Label': labels\n",
        "})\n",
        "\n",
        "# Save to CSV\n",
        "labels_file_path = '/content/drive/MyDrive/ADD_ASV_DATA/LA/ASVspoof2019_LA_train/labels.csv'\n",
        "labels_df.to_csv(labels_file_path, index=False)\n",
        "\n",
        "print(f\"Labels file created at {labels_file_path}.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "H9dA97WRy4PS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1068570c-0ea1-4c2d-d434-f35af9e1d922"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted features for 5160 files.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import librosa\n",
        "import numpy as np\n",
        "\n",
        "# Load labels file\n",
        "labels_df = pd.read_csv('/content/drive/MyDrive/ADD_ASV_DATA/LA/ASVspoof2019_LA_train/labels.csv')\n",
        "labels_dict = dict(zip(labels_df['FileName'], labels_df['Label']))\n",
        "\n",
        "# Define path to the new folder with sampled files\n",
        "new_folder_path = '/content/drive/MyDrive/ADD_ASV_DATA/LA/ASVspoof2019_LA_train/ASVspoof2019_LA_Sampled'\n",
        "\n",
        "# Function to extract MFCC features\n",
        "def extract_features(file_path):\n",
        "    audio, sr = librosa.load(file_path, sr=None)\n",
        "    mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13)\n",
        "    mfccs = np.mean(mfccs.T, axis=0)\n",
        "    return mfccs\n",
        "\n",
        "# Extract features for each sampled file\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "for file_name in labels_df['FileName']:\n",
        "    file_path = f'{new_folder_path}/{file_name}.flac'\n",
        "    try:\n",
        "        features = extract_features(file_path)\n",
        "        X.append(features)\n",
        "        label = labels_dict.get(file_name)\n",
        "        y.append(label)\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing file {file_name}: {e}\")\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "print(f\"Extracted features for {len(X)} files.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "cSN0Iby7zqhF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bd848c2-28f9-452b-c2e2-22957e243e1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data size: 4128\n",
            "Testing data size: 1032\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Training data size: {X_train.shape[0]}\")\n",
        "print(f\"Testing data size: {X_test.shape[0]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "oOMT1Z_10cSl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "965c78f5-5035-41a1-e816-7d2647c9af09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8042635658914729\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.86      0.82       522\n",
            "           1       0.84      0.75      0.79       510\n",
            "\n",
            "    accuracy                           0.80      1032\n",
            "   macro avg       0.81      0.80      0.80      1032\n",
            "weighted avg       0.81      0.80      0.80      1032\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Standardize features by scaling\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Create SVM model\n",
        "svm_model = make_pipeline(scaler, SVC(kernel='linear', random_state=42))\n",
        "\n",
        "# Train the model\n",
        "svm_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = svm_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##To Improve accuracy further Feature Engineering and Selection.\n",
        "\n",
        "\n",
        "Increase the number of features: Extract more audio features besides MFCCs, such as chroma features, spectral contrast, or tonnetz features."
      ],
      "metadata": {
        "id": "zUTOfLOaOVHs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "QSTnSwEa0guX"
      },
      "outputs": [],
      "source": [
        "def extract_features(new_folder_path):\n",
        "    audio, sr = librosa.load(new_folder_path, sr=None)\n",
        "    mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13)\n",
        "    chroma = librosa.feature.chroma_stft(y=audio, sr=sr)\n",
        "    spectral_contrast = librosa.feature.spectral_contrast(y=audio, sr=sr)\n",
        "    tonnetz = librosa.feature.tonnetz(y=audio, sr=sr)\n",
        "\n",
        "    features = np.hstack([\n",
        "        np.mean(mfccs.T, axis=0),\n",
        "        np.mean(chroma.T, axis=0),\n",
        "        np.mean(spectral_contrast.T, axis=0),\n",
        "        np.mean(tonnetz.T, axis=0)\n",
        "    ])\n",
        "    return features\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Normalize Features:\n",
        "Ensure that features are standardized."
      ],
      "metadata": {
        "id": "kPsEdcecPbyz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "NfHifjhJ9Z_D"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Hyperparameter Tuning:\n",
        "Perform a Grid Search or Random Search to find the best hyperparameters for the SVM model."
      ],
      "metadata": {
        "id": "CmhfC5-fPaes"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "YmM2j0J59aar",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61c27c23-5261-4682-ca50-9d5aca39bc4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters found: {'svc__C': 10, 'svc__gamma': 0.1, 'svc__kernel': 'rbf'}\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "svm_model = make_pipeline(StandardScaler(), SVC(random_state=42))\n",
        "param_grid = {\n",
        "    'svc__C': [0.1, 1, 10],\n",
        "    'svc__gamma': [0.001, 0.01, 0.1, 1],\n",
        "    'svc__kernel': ['linear', 'rbf']\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(estimator=svm_model, param_grid=param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best parameters found:\", grid_search.best_params_)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Experiment with Different Kernels:"
      ],
      "metadata": {
        "id": "Vvkz527rPtbs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "p7GXQwR29c8v"
      },
      "outputs": [],
      "source": [
        "svm_model = make_pipeline(StandardScaler(), SVC(kernel='rbf', random_state=42))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Perform Cross-Validation:\n",
        "Use cross-validation to evaluate the model's performance more robustly."
      ],
      "metadata": {
        "id": "09xIiRzsP92t"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "HM_KmknY90p6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48e3daee-eeef-4d32-bd65-ee84c8c1f3f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-validation scores: [0.92829457 0.92829457 0.92635659 0.93023256 0.92344961]\n",
            "Mean CV score: 0.9273255813953488\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "scores = cross_val_score(svm_model, X, y, cv=5, scoring='accuracy')\n",
        "print(\"Cross-validation scores:\", scores)\n",
        "print(\"Mean CV score:\", np.mean(scores))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Handle Class Imbalance\n",
        "Use oversampling or undersampling techniques if your dataset is imbalanced."
      ],
      "metadata": {
        "id": "dJ3MnNaJQG-0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "RuCWarSA92id",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "aebfb93b-5fd9-4aaf-e5b6-32782972a9ba"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
              "                ('svc', SVC(random_state=42))])"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),\n",
              "                (&#x27;svc&#x27;, SVC(random_state=42))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),\n",
              "                (&#x27;svc&#x27;, SVC(random_state=42))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(random_state=42)</pre></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "svm_model.fit(X_resampled, y_resampled)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " ## Model Evaluation\n"
      ],
      "metadata": {
        "id": "gNPxSA2KQJal"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "aR6ahYpm96e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13bae205-6b8e-406f-e476-935c36bfb618"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9215116279069767\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.95      0.92       522\n",
            "           1       0.94      0.90      0.92       510\n",
            "\n",
            "    accuracy                           0.92      1032\n",
            "   macro avg       0.92      0.92      0.92      1032\n",
            "weighted avg       0.92      0.92      0.92      1032\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "y_pred = svm_model.predict(X_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save Model"
      ],
      "metadata": {
        "id": "QjMWcIDdQdZQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "boHGmBUU9_xL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca04ddd6-9ab5-4c2f-a066-4ba04c51de54"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/ADD_ASV_DATA/LA/ASVspoof2019_LA_train/svm_model.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "import joblib\n",
        "\n",
        "# Save the trained model to a file\n",
        "joblib.dump(svm_model, '/content/drive/MyDrive/ADD_ASV_DATA/LA/ASVspoof2019_LA_train/svm_model.pkl')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Model"
      ],
      "metadata": {
        "id": "dd5dUUAeQhR6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "h5GRBVFl_TIK"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "svm_model = joblib.load('/content/drive/MyDrive/ADD_ASV_DATA/LA/ASVspoof2019_LA_train/svm_model.pkl')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5nWpHR_RBx8S"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}