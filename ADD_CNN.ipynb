{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fnch5Vk_iFR",
        "outputId": "36363eae-26a0-433d-be28-5a08a089c7c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of bonafide files: 2580\n",
            "Number of spoof files: 22800\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Paths\n",
        "protocol_file_path = '/content/drive/MyDrive/ADD_ASV_DATA/LA/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.train.trn.txt'\n",
        "\n",
        "# Load the protocol file\n",
        "protocol_df = pd.read_csv(protocol_file_path, delim_whitespace=True, header=None,\n",
        "                          names=['SpeakerID', 'FileName', 'Env', 'Label', 'SpoofType'])\n",
        "\n",
        "# Count the number of bonafide and spoof files\n",
        "bonafide_count = protocol_df[protocol_df['SpoofType'] == 'bonafide'].shape[0]\n",
        "spoof_count = protocol_df[protocol_df['SpoofType'] == 'spoof'].shape[0]\n",
        "\n",
        "print(f\"Number of bonafide files: {bonafide_count}\")\n",
        "print(f\"Number of spoof files: {spoof_count}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4woFV6G02llG"
      },
      "source": [
        "##Data Augmentation\n",
        "Our original dataset had significantly more spoof files (22,800) compared to bonafide files (2,580). This imbalance could lead to biased model training, where the model might become overly sensitive to the majority class (spoof) and underperform on the minority class (bonafide). By augmenting the bonafide files, we increased their number from 2,580 to 7,422. Using data augmentation, we improved our dataset's balance and size, which is expected to enhance the performance and reliability of our CNN model in detecting deepfake audio."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2s7Rx0UJuFci",
        "outputId": "c5f078d2-bb39-4e07-ad3a-0a26f8be9aa5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Augmented bonafide files saved to /content/drive/MyDrive/ADD_ASV_DATA/LA/ASVspoof2019_LA_train/ADD_CNN/augmented_bonafide and labels saved to /content/drive/MyDrive/ADD_ASV_DATA/LA/ASVspoof2019_LA_train/augmented_bonafide_labels.csv\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "import random\n",
        "\n",
        "# Paths\n",
        "audio_files_dir = '/content/drive/MyDrive/ADD_ASV_DATA/LA/ASVspoof2019_LA_train/flac'  # Original bonafide files directory\n",
        "output_augmented_dir = '/content/drive/MyDrive/ADD_ASV_DATA/LA/ASVspoof2019_LA_train/ADD_CNN/augmented_bonafide'  # Augmented files directory\n",
        "csv_output_path = '/content/drive/MyDrive/ADD_ASV_DATA/LA/ASVspoof2019_LA_train/augmented_bonafide_labels.csv'\n",
        "\n",
        "# Create the output directory if it doesn't exist\n",
        "if not os.path.exists(output_augmented_dir):\n",
        "    os.makedirs(output_augmented_dir)\n",
        "\n",
        "# Load the bonafide files\n",
        "protocol_file_path = '/content/drive/MyDrive/ADD_ASV_DATA/LA/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.train.trn.txt'\n",
        "protocol_df = pd.read_csv(protocol_file_path, delim_whitespace=True, header=None,\n",
        "                          names=['SpeakerID', 'FileName', 'Env', 'Label', 'SpoofType'])\n",
        "\n",
        "bonafide_files = protocol_df[protocol_df['SpoofType'] == 'bonafide']['FileName']\n",
        "\n",
        "# Perform data augmentation on the bonafide files\n",
        "def augment_audio(file_path):\n",
        "    y, sr = librosa.load(file_path, sr=None)  # Load the file with its original sampling rate\n",
        "\n",
        "    # Random pitch shift\n",
        "    pitch_shifted = librosa.effects.pitch_shift(y, sr=sr, n_steps=random.uniform(-2, 2))\n",
        "\n",
        "    # Random time stretch (factor between 0.8 and 1.2)\n",
        "    time_stretch_factor = random.uniform(0.8, 1.2)\n",
        "    if time_stretch_factor != 1.0:  # Ensure we only stretch when the factor is not 1.0\n",
        "        time_stretched = librosa.effects.time_stretch(y, rate=time_stretch_factor)\n",
        "    else:\n",
        "        time_stretched = y\n",
        "\n",
        "    # Add white noise\n",
        "    noise_amp = 0.005 * np.random.uniform() * np.amax(y)\n",
        "    noise_added = y + noise_amp * np.random.normal(size=y.shape)\n",
        "\n",
        "    return [pitch_shifted, time_stretched, noise_added], sr  # Return both augmented audio and sr\n",
        "\n",
        "# Save the augmented files and their labels\n",
        "labels = []\n",
        "file_counter = 2580  # Start file numbering from 2580, since 2580 original files already exist\n",
        "\n",
        "for i, file_name in enumerate(bonafide_files):\n",
        "    file_path = os.path.join(audio_files_dir, f\"{file_name}.flac\")\n",
        "\n",
        "    # Generate 3 augmented versions for each file\n",
        "    augmented_versions, sr = augment_audio(file_path)  # Get augmented files and sampling rate\n",
        "\n",
        "    for aug_idx, augmented_audio in enumerate(augmented_versions):\n",
        "        new_file_name = f\"bonafide_aug_{file_counter}.flac\"\n",
        "        new_file_path = os.path.join(output_augmented_dir, new_file_name)\n",
        "\n",
        "        # Save the augmented audio file\n",
        "        sf.write(new_file_path, augmented_audio, sr)  # Save the file with the original sampling rate\n",
        "\n",
        "        # Append filename and label (0 for bonafide)\n",
        "        labels.append([new_file_name, 0])\n",
        "\n",
        "        file_counter += 1\n",
        "\n",
        "    # Stop if we reach around 10,000 files\n",
        "    if file_counter >= 10000:\n",
        "        break\n",
        "\n",
        "# Save the labels to a CSV file\n",
        "labels_df = pd.DataFrame(labels, columns=['FileName', 'Label'])\n",
        "labels_df.to_csv(csv_output_path, index=False)\n",
        "\n",
        "print(f\"Augmented bonafide files saved to {output_augmented_dir} and labels saved to {csv_output_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Js_rsG4cwUtt",
        "outputId": "39814197-79ca-4597-9932-83a0c6acce76"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of bonafide files: 7422\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Path to the directory containing bonafide files\n",
        "augmented_bonafide_dir = '/content/drive/MyDrive/ADD_ASV_DATA/LA/ASVspoof2019_LA_train/ADD_CNN/augmented_bonafide'\n",
        "\n",
        "# Count the number of .flac files in the directory\n",
        "bonafide_files_count = len([f for f in os.listdir(augmented_bonafide_dir) if f.endswith('.flac')])\n",
        "\n",
        "print(f\"Number of bonafide files: {bonafide_files_count}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a new dataset with 7,500 spoof files from the original dataset and all 7,422 bonafide files from the newly created set and then shuffle the combined dataset and also generate a labels CSV file."
      ],
      "metadata": {
        "id": "iSJGARNYZ1ef"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "GMbu9eUUCOT7",
        "outputId": "df86cd20-3622-4c0a-b4a3-bad4ea052919"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final sample data saved to /content/drive/MyDrive/ADD_ASV_DATA/LA/ASVspoof2019_LA_train/ADD_CNN/final_sample_dir and labels saved to /content/drive/MyDrive/ADD_ASV_DATA/LA/ASVspoof2019_LA_train/ADD_CNN/final_labels.csv\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "# Paths\n",
        "augmented_bonafide_dir = '/content/drive/MyDrive/ADD_ASV_DATA/LA/ASVspoof2019_LA_train/ADD_CNN/augmented_bonafide/augmented_bonafide_flac'\n",
        "original_data_dir = '/content/drive/MyDrive/ADD_ASV_DATA/LA/ASVspoof2019_LA_train/flac'  # Directory with both bonafide and spoof files\n",
        "final_sample_dir = '/content/drive/MyDrive/ADD_ASV_DATA/LA/ASVspoof2019_LA_train/ADD_CNN/final_sample_dir'\n",
        "final_labels_csv = '/content/drive/MyDrive/ADD_ASV_DATA/LA/ASVspoof2019_LA_train/ADD_CNN/final_labels.csv'\n",
        "\n",
        "# Create the final sample directory if it doesn't exist\n",
        "if not os.path.exists(final_sample_dir):\n",
        "    os.makedirs(final_sample_dir)\n",
        "\n",
        "# Load the bonafide files\n",
        "bonafide_files = [f for f in os.listdir(augmented_bonafide_dir) if f.endswith('.flac')]\n",
        "\n",
        "# Ensure we have 7,422 bonafide files\n",
        "assert len(bonafide_files) == 7422, \"The number of bonafide files is not as expected.\"\n",
        "\n",
        "# Separate spoof files from the original data directory\n",
        "all_files = [f for f in os.listdir(original_data_dir) if f.endswith('.flac')]\n",
        "protocol_file_path = '/content/drive/MyDrive/ADD_ASV_DATA/LA/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.train.trn.txt'\n",
        "protocol_df = pd.read_csv(protocol_file_path, delim_whitespace=True, header=None,\n",
        "                          names=['SpeakerID', 'FileName', 'Env', 'Label', 'SpoofType'])\n",
        "\n",
        "# Create a mapping of file names to their spoof type\n",
        "file_spoof_map = dict(zip(protocol_df['FileName'], protocol_df['SpoofType']))\n",
        "\n",
        "# Filter spoof files\n",
        "spoof_files = [f for f in all_files if file_spoof_map.get(f[:-5], '') == 'spoof']  # Remove '.flac' for matching\n",
        "\n",
        "# Ensure we have 7,500 spoof files\n",
        "assert len(spoof_files) >= 7500, \"Not enough spoof files.\"\n",
        "\n",
        "# Randomly select 7,500 spoof files (if more are available)\n",
        "spoof_files = random.sample(spoof_files, 7500)\n",
        "\n",
        "# Copy selected bonafide files to final sample directory\n",
        "bonafide_labels = []\n",
        "for file_name in bonafide_files:\n",
        "    src_path = os.path.join(augmented_bonafide_dir, file_name)\n",
        "    dst_path = os.path.join(final_sample_dir, file_name)\n",
        "    shutil.copy(src_path, dst_path)\n",
        "    bonafide_labels.append([file_name, 0])  # 0 for bonafide\n",
        "\n",
        "# Copy selected spoof files to final sample directory\n",
        "spoof_labels = []\n",
        "for file_name in spoof_files:\n",
        "    src_path = os.path.join(original_data_dir, file_name)\n",
        "    dst_path = os.path.join(final_sample_dir, file_name)\n",
        "    shutil.copy(src_path, dst_path)\n",
        "    spoof_labels.append([file_name, 1])  # 1 for spoof\n",
        "\n",
        "# Combine and shuffle all files\n",
        "all_files = bonafide_files + spoof_files\n",
        "all_labels = bonafide_labels + spoof_labels\n",
        "combined = list(zip(all_files, all_labels))\n",
        "random.shuffle(combined)\n",
        "\n",
        "# Separate files and labels after shuffling\n",
        "shuffled_files, shuffled_labels = zip(*combined)\n",
        "\n",
        "# Create labels DataFrame\n",
        "labels_df = pd.DataFrame(shuffled_labels, columns=['FileName', 'Label'])\n",
        "\n",
        "# Save the labels to a CSV file\n",
        "labels_df.to_csv(final_labels_csv, index=False)\n",
        "\n",
        "print(f\"Final sample data saved to {final_sample_dir} and labels saved to {final_labels_csv}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Paths\n",
        "final_labels_csv = '/content/drive/MyDrive/ADD_ASV_DATA/LA/ASVspoof2019_LA_train/ADD_CNN/final_labels.csv'\n",
        "\n",
        "# Load the labels CSV\n",
        "labels_df = pd.read_csv(final_labels_csv)\n",
        "\n",
        "# Count the number of bonafide and spoof files\n",
        "bonafide_count = len(labels_df[labels_df['Label'] == 0])  # Bonafide files (label 0)\n",
        "spoof_count = len(labels_df[labels_df['Label'] == 1])  # Spoof files (label 1)\n",
        "\n",
        "print(f\"Number of bonafide files: {bonafide_count}\")\n",
        "print(f\"Number of spoof files: {spoof_count}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukY6wLwvXHwz",
        "outputId": "ceef3e08-cfc0-4ed8-b6c0-0df2576da58b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of bonafide files: 7422\n",
            "Number of spoof files: 7500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Path to the final sample directory\n",
        "final_sample_dir = '/content/drive/MyDrive/ADD_ASV_DATA/LA/ASVspoof2019_LA_train/ADD_CNN/final_sample_dir'\n",
        "\n",
        "# Count the number of files in the directory (excluding hidden files)\n",
        "file_count = len([f for f in os.listdir(final_sample_dir) if f.endswith('.flac')])\n",
        "\n",
        "print(f\"Number of files in final_sample_dir: {file_count}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "if6JYkRTXLse",
        "outputId": "90b38db1-8a9b-40ba-e30d-a5e7e0688890"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of files in final_sample_dir: 14922\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install librosa matplotlib\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wGaXEBTXXBj",
        "outputId": "ae54e885-bed7-4780-c52c-fc181fab39b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (0.10.2.post1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.3.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.12.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.12.2)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.0.8)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa) (4.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa) (2.32.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa) (1.17.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Convert Audio to Mel-Spectrograms\n",
        "\n",
        " Mel-spectrograms, which are essentially visual representations of sound and can be treated as image data for CNN training.\n",
        "\n"
      ],
      "metadata": {
        "id": "opUpZChyaQm_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import librosa\n",
        "import librosa.display\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define directories\n",
        "audio_dir = '/content/drive/MyDrive/ADD_ASV_DATA/LA/ASVspoof2019_LA_train/ADD_CNN/final_sample_dir'\n",
        "output_spectrogram_dir = '/content/drive/MyDrive/ADD_ASV_DATA/LA/ASVspoof2019_LA_train/ADD_CNN/output_spectrogram_dir'\n",
        "\n",
        "# Create the output directory if it doesn't exist\n",
        "if not os.path.exists(output_spectrogram_dir):\n",
        "    os.makedirs(output_spectrogram_dir)\n",
        "\n",
        "# Function to convert audio to mel-spectrogram\n",
        "def audio_to_melspectrogram(file_path, output_image_path):\n",
        "    y, sr = librosa.load(file_path, sr=None)  # Load audio file\n",
        "    mel_spec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128, fmax=8000)  # Compute mel-spectrogram\n",
        "\n",
        "    # Convert to log scale (dB)\n",
        "    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
        "\n",
        "    # Plot and save as image\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    librosa.display.specshow(mel_spec_db, sr=sr, x_axis='time', y_axis='mel', fmax=8000)\n",
        "    plt.colorbar(format='%+2.0f dB')\n",
        "    plt.title('Mel-spectrogram')\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Save the figure as an image file (PNG)\n",
        "    plt.savefig(output_image_path, bbox_inches='tight', pad_inches=0)\n",
        "    plt.close()\n",
        "\n",
        "# Process files in batches\n",
        "batch_size = 1000\n",
        "file_list = [f for f in os.listdir(audio_dir) if f.endswith('.flac')]\n",
        "total_files = len(file_list)\n",
        "\n",
        "# Load the last processed file if any\n",
        "last_processed_file = 0\n",
        "checkpoint_file = 'checkpoint.txt'\n",
        "if os.path.exists(checkpoint_file):\n",
        "    with open(checkpoint_file, 'r') as f:\n",
        "        last_processed_file = int(f.read().strip())\n",
        "\n",
        "# Process the files starting from the last checkpoint\n",
        "for idx in range(last_processed_file, total_files, batch_size):\n",
        "    for file_name in file_list[idx:idx + batch_size]:\n",
        "        file_path = os.path.join(audio_dir, file_name)\n",
        "        output_image_path = os.path.join(output_spectrogram_dir, file_name.replace('.flac', '.png'))\n",
        "        audio_to_melspectrogram(file_path, output_image_path)\n",
        "\n",
        "    # Save progress\n",
        "    with open(checkpoint_file, 'w') as f:\n",
        "        f.write(str(idx + batch_size))\n",
        "\n",
        "    print(f\"Processed files {idx + 1} to {min(idx + batch_size, total_files)} out of {total_files}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcbYfN0iDIoQ",
        "outputId": "e98e6746-123f-4983-9d64-7ded0b349abc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed files 12001 to 13000 out of 14922\n",
            "Processed files 13001 to 14000 out of 14922\n",
            "Processed files 14001 to 14922 out of 14922\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Path to the final sample directory\n",
        "final_sample_dir = '/content/drive/MyDrive/ADD_ASV_DATA/LA/ASVspoof2019_LA_train/ADD_CNN/output_spectrogram_dir'\n",
        "\n",
        "# Initialize counters\n",
        "bonafide_count = 0\n",
        "spoof_count = 0\n",
        "\n",
        "# Iterate over files in the directory\n",
        "for file_name in os.listdir(final_sample_dir):\n",
        "    if file_name.endswith('.png'):  # Only consider .png files\n",
        "        if file_name.startswith('bonafide_aug'):  # Bonafide files naming convention\n",
        "            bonafide_count += 1\n",
        "        elif file_name.startswith('LA_T'):  # Spoof files naming convention\n",
        "            spoof_count += 1\n",
        "\n",
        "# Print the results\n",
        "print(f\"Number of bonafide files: {bonafide_count}\")\n",
        "print(f\"Number of spoof files: {spoof_count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D93h3eOtWmMZ",
        "outputId": "eac96148-c738-43d0-cf13-6c43b8c483f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of bonafide files: 7422\n",
            "Number of spoof files: 7500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Update Labels CSV to Reflect Spectrograms"
      ],
      "metadata": {
        "id": "ws-FHVFZ40r8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Define paths\n",
        "labels_csv_path = '/content/drive/MyDrive/ADD_ASV_DATA/LA/ASVspoof2019_LA_train/ADD_CNN/final_labels.csv'\n",
        "output_spectrogram_dir = '/content/drive/MyDrive/ADD_ASV_DATA/LA/ASVspoof2019_LA_train/ADD_CNN/output_spectrogram_dir'\n",
        "\n",
        "# Load the existing labels CSV\n",
        "labels_df = pd.read_csv(labels_csv_path)\n",
        "\n",
        "# Ensure that labels match the spectrogram images\n",
        "spectrogram_files = [f for f in os.listdir(output_spectrogram_dir) if f.endswith('.png')]\n",
        "spectrogram_files_set = set(f.replace('.png', '') for f in spectrogram_files)\n",
        "\n",
        "# Filter labels to include only files that have corresponding spectrograms\n",
        "filtered_labels_df = labels_df[labels_df['FileName'].str.replace('.flac', '').isin(spectrogram_files_set)]\n",
        "\n",
        "# Save the updated labels CSV\n",
        "updated_labels_csv_path = '/content/drive/MyDrive/ADD_ASV_DATA/LA/ASVspoof2019_LA_train/ADD_CNN/updated_labels.csv'\n",
        "filtered_labels_df.to_csv(updated_labels_csv_path, index=False)\n",
        "\n",
        "print(f\"Updated labels CSV saved to {updated_labels_csv_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Bei6Le1ZYQX",
        "outputId": "15295deb-b86f-45c2-8a82-d95c44b7c3cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated labels CSV saved to /content/drive/MyDrive/ADD_ASV_DATA/LA/ASVspoof2019_LA_train/ADD_CNN/updated_labels.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Define directories\n",
        "spectrogram_dir = '/content/drive/MyDrive/ADD_ASV_DATA/LA/ASVspoof2019_LA_train/ADD_CNN/output_spectrogram_dir'\n",
        "processed_spectrogram_dir = '/content/drive/MyDrive/ADD_ASV_DATA/LA/ASVspoof2019_LA_train/ADD_CNN/processed_spectrogram_dir'\n",
        "\n",
        "# Create output directory if it doesn't exist\n",
        "if not os.path.exists(processed_spectrogram_dir):\n",
        "    os.makedirs(processed_spectrogram_dir)\n",
        "\n",
        "# Function to normalize an image to the [0, 1] range\n",
        "def normalize_image(image):\n",
        "    normalized_image = image.astype('float32') / 255.0\n",
        "    return normalized_image\n",
        "\n",
        "# Process each image file\n",
        "for file_name in os.listdir(spectrogram_dir):\n",
        "    if file_name.endswith('.png'):\n",
        "        file_path = os.path.join(spectrogram_dir, file_name)\n",
        "\n",
        "        # Load the image\n",
        "        img = cv2.imread(file_path)\n",
        "\n",
        "        # Normalize the image to [0, 1]\n",
        "        img_normalized = normalize_image(img)\n",
        "\n",
        "        # Save the normalized image (optional, can skip saving and just use in-memory if needed)\n",
        "        output_image_path = os.path.join(processed_spectrogram_dir, file_name)\n",
        "        cv2.imwrite(output_image_path, (img_normalized * 255).astype(np.uint8))  # Saving it back as a PNG\n",
        "\n",
        "print(\"Normalization of spectrograms completed!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "laJ75W-_afot",
        "outputId": "06a1354d-d12b-43ca-b81a-364178835a4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalization of spectrograms completed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data Loading and Preprocessing\n",
        "\n"
      ],
      "metadata": {
        "id": "t0szvZ2SbTIU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Custom dataset class for loading spectrogram images and labels\n",
        "class SpoofDataset(Dataset):\n",
        "    def __init__(self, image_dir, labels_csv, transform=None):\n",
        "        self.image_dir = image_dir\n",
        "        self.labels_df = pd.read_csv(labels_csv)\n",
        "        self.file_to_label = dict(zip(self.labels_df['FileName'], self.labels_df['Label']))\n",
        "        self.image_files = [f for f in os.listdir(image_dir) if f.endswith('.png')]\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.image_files[idx]\n",
        "        img_path = os.path.join(self.image_dir, img_name)\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "\n",
        "        # Apply transformations if provided\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        label = self.file_to_label[img_name.replace('.png', '.flac')]\n",
        "        return image, label\n",
        "\n",
        "# Define the image transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor(),  # Converts to tensor\n",
        "])\n",
        "\n",
        "# Paths\n",
        "image_dir = '/content/drive/MyDrive/ADD_ASV_DATA/LA/ASVspoof2019_LA_train/ADD_CNN/resized_dataset_folder'\n",
        "labels_csv = '/content/drive/MyDrive/ADD_ASV_DATA/LA/ASVspoof2019_LA_train/ADD_CNN/updated_labels.csv'\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = SpoofDataset(image_dir, labels_csv, transform=transform)\n",
        "\n",
        "# Create data loaders\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n"
      ],
      "metadata": {
        "id": "QZV3TPYU25hJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Define the CNN Model"
      ],
      "metadata": {
        "id": "QqK1WdPrMOG7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CNNModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNNModel, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.fc1 = nn.Linear(128 * 32 * 32, 512)  # Adjust input size based on final conv output\n",
        "        self.fc2 = nn.Linear(512, 1)  # Binary classification\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = self.pool(F.relu(self.conv3(x)))\n",
        "        x = x.view(-1, 128 * 32 * 32)  # Flatten\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = torch.sigmoid(self.fc2(x))  # Sigmoid for binary classification\n",
        "        return x\n",
        "\n",
        "model = CNNModel()\n"
      ],
      "metadata": {
        "id": "s0T5DFli3OE_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Training Loop"
      ],
      "metadata": {
        "id": "hZW4xuGZMUsU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.BCELoss()  # Use binary cross-entropy loss\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Check if GPU is available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    model.train()  # Set the model to training mode\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device).float()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images).squeeze()\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Calculate accuracy\n",
        "        predicted = (outputs > 0.5).float()\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}, Accuracy: {100 * correct / total:.2f}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3AaEMldG3Q5l",
        "outputId": "5332704d-2dc4-491a-f52d-b021904448e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.2371, Accuracy: 90.07%\n",
            "Epoch [2/10], Loss: 0.0783, Accuracy: 97.12%\n",
            "Epoch [3/10], Loss: 0.0421, Accuracy: 98.40%\n",
            "Epoch [4/10], Loss: 0.0248, Accuracy: 99.09%\n",
            "Epoch [5/10], Loss: 0.0210, Accuracy: 99.30%\n",
            "Epoch [6/10], Loss: 0.0129, Accuracy: 99.50%\n",
            "Epoch [7/10], Loss: 0.0069, Accuracy: 99.75%\n",
            "Epoch [8/10], Loss: 0.0074, Accuracy: 99.75%\n",
            "Epoch [9/10], Loss: 0.0109, Accuracy: 99.62%\n",
            "Epoch [10/10], Loss: 0.0050, Accuracy: 99.81%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "\n",
        "# Custom dataset class\n",
        "class SpectrogramDataset(Dataset):\n",
        "    def __init__(self, image_dir, file_to_label, transform=None):\n",
        "        self.image_dir = image_dir\n",
        "        self.file_to_label = file_to_label\n",
        "        self.image_files = [f for f in os.listdir(image_dir) if f.endswith('.png')]\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.image_files[idx]\n",
        "        img_path = os.path.join(self.image_dir, img_name)\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        label = self.file_to_label.get(img_name.replace('.png', '.flac'), -1)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, torch.tensor(label, dtype=torch.float32)\n",
        "\n",
        "# Assuming you have already a transform (resizing and normalization)\n",
        "from torchvision import transforms\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize to [-1, 1]\n",
        "])\n",
        "\n",
        "# Create the PyTorch dataset for test data\n",
        "test_dataset = SpectrogramDataset(spectrogram_dir, file_to_label, transform=transform)\n",
        "\n",
        "# Create the DataLoader for test data\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
      ],
      "metadata": {
        "id": "nGdpmh2j-K6k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Evaluate Model on Test Data"
      ],
      "metadata": {
        "id": "nntcEsUlMfUP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():  # Disable gradient calculation for evaluation\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images).squeeze()\n",
        "        predicted = (outputs > 0.5).float()  # Binary classification\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Test Accuracy: {100 * correct / total:.2f}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OxJOP_GL_2aQ",
        "outputId": "80fea2c2-efea-44e2-bf41-dc3f7886bff5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 50.26%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A test accuracy of 50.26% suggests that model is performing similarly to random guessing, especially if you have a binary classification problem. So now due to less test accuracy, we will go with approach of using RES-EfficientCNN (ResNet-Efficient Convolutional Neural Network)"
      ],
      "metadata": {
        "id": "0cbhWtEdMyOq"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
